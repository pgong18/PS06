---
title: 'STAT/MATH 495: Problem Set 06'
author: "Pei Gong"
date: '2017-10-17'
output:
  html_document:
    collapsed: no
    df_print: kable
    smooth_scroll: no
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
```

# Collaboration

Please indicate who you collaborated with on this assignment: Independent 


# Setup

Define truth, which again we know for the purposes of this assignment, but in
practice we won't:

* the true function f(x) i.e. the signal
* the true epsilon i.e. the noise, which in this case is Normal$(0, sd=\sigma)$.
Hence the standard deviation $\sigma$ determines the amount of noise.

```{r}
f <- function(x) {
  x^2
}
sigma <- 0.3
```

This is the target point we'll be trying to predict: $(0.95, f(0.95)) = (0.95, 0.95^2) = (0.95, 0.9025)$, Thus, the test set is just `x=0.95`

```{r}
x0 <- 0.95
y0<-x0^2
test_set <- data_frame(x=x0)
```

This function generates a random sample of size $n$; think of this as a "get new
data" function. Random in terms of both:

* (New) the predictor x (uniform on [0,1])
* the amount of noise $\epsilon$

```{r}
generate_sample <- function(f, n, sigma) {
  sample <- data_frame(
    x = runif(n = n, min = 0, max = 1),
    f_x = f(x),
    epsilon = rnorm(n = n, mean = 0, sd = sigma),
    y = f_x + epsilon
  )
  # Recall: We don't observe f(x) and epsilon, just (x, y)
  sample <- sample %>% 
    select(x, y)
  return(sample)
}
```


Define

* The number $n$ of observations $(x_i, y_i)$ in each sample. In the handout,
$n=100$ to keep plots uncrowded. Here we boost to $n=500$
* Number of samples of size $n$ to consider

```{r}
n <- 500
n_sample <- 10000
```

# Computation

```{r}
predict_y<-runif(n = n_sample, min = 1, max = 2)
SE<-runif(n = n_sample, min = 1, max = 2)
```


```{r}
calculate<-function(n_sample,dfreedom){
   for (i in c(1:n_sample)){
    sample_single<-generate_sample(f,n,sigma)
    model<-smooth.spline(sample_single$x,sample_single$y,df=dfreedom)
    predict_y[i]<-predict(x=x0,model)$y
    y_real<-rnorm(1,y0,sigma)
    SE[i]<-(predict(x=x0,model)$y-y_real)^2
   }
    MSE_total<-mean(SE)
    variance_total<-var(predict_y)
    bias_squared_total<-(y0-mean(predict_y))^2
  return(c(MSE_total,variance_total,bias_squared_total))
}
```
    

# Tables


df=2

```{r}
predictions_2<-calculate(n_sample,2);predictions_2
sum_2<-predictions_2[2]+predictions_2[3]+sigma^2;sum_2
```

|  MSE| bias_squared|   var| irreducible|   sum|
|----:|------------:|-----:|-----------:|-----:|
|    0.1018664 |  0.013879 | 0.000666| 0.09 | 0.10454|

df=99

```{r}
predictions_99<-calculate(n_sample,99);predictions_99
sum_99<-predictions_99[2]+predictions_99[3]+sigma^2;sum_99
```

|  MSE| bias_squared|   var| irreducible|   sum|
|----:|------------:|-----:|-----------:|-----:|
|    0.1085 |  0.00000 | 0.0182| 0.09 |  0.1082|

# Analysis

**Questions**:

1. Based on the topics covered in Lec 2.7, name one possible "sanity check" for your results. Name another if you can.
1. In **two** sentences or less, give a rough sketch of what the procedure would
be to get the breakdown of $$\mbox{MSE}\left[\widehat{f}(x)\right]$$ for *all*
$x$ in this example, and not just for $$\mbox{MSE}\left[\widehat{f}(x_0)\right]
= \mbox{MSE}\left[\widehat{f}(0.95)\right]$$.
1. Which of the two models would you choose for predicting the point of interest and why?

**Answers**:  

1. Assuming repeating the above procedure infinite number of times, 
$$\mbox{MSE}\left[\widehat{f}(x_0)\right]=\mbox{Var}\left[\widehat{f}(x_0)\right]+(\mbox{Bias}\left[\widehat{f}(x_0)\right])^2+\sigma^2$$. As shown above, one possible "sanity check" would be to see if sum=bias_square+var+irreducible is approximately equal to MSE. 

2. Create a for loop within the xisiting for loop that loops through all the values of x. MSE, bias^2 and variance will be computed based on all x values.  

3. I would use df=2 to predict the point of interest. It is more biased but also less varied.Because the less in variation, we are confident that the predicted $\hat{y}$ is probably around 1 $bias$=$\sqrt{0.013885}$ away from real $y$. In contrast,  with df=99, we are not sure how far off the predicted value is from the real value because of the high variance.  